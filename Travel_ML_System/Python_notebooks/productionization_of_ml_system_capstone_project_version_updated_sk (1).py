# -*- coding: utf-8 -*-
"""Productionization of ML System Capstone Project version updated SK.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WUEk85koVvjpB9nB9Akj3v6radQWeXwy

#**Importing Necessary Libraries**
"""

!pip install flask

# !pip uninstall xgboost

# !pip install xgboost==1.6.2

# !pip uninstall scikit-learn
# !pip install scikit-learn==1.2.2

!pip install blinker

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import warnings
warnings.filterwarnings("ignore")

!pip install flask_ngrok pyngrok sentence-transformers

# pip install --force-reinstall --ignore-installed flask-ngrok

from pyngrok import ngrok
from flask_ngrok import run_with_ngrok
from flask import Flask, render_template, request, jsonify
!ngrok authtoken "2lQehFbtavcCd2ux1ynNPHc4lJo_6Jzm1pDJiKyKvtMMfZnTu"

"""

#**Data Loading**"""

from google.colab import drive
drive.mount('/content/drive')

flight_df=pd.read_csv("/content/drive/MyDrive/travel_capstone/flights.csv",on_bad_lines='skip')
hotel_df=pd.read_csv("/content/drive/MyDrive/travel_capstone/hotels.csv",on_bad_lines='skip')
user_df=pd.read_csv("/content/drive/MyDrive/travel_capstone/users.csv",on_bad_lines='skip')

flight_df.head()

"""
#**Data Mining and Exploration**"""

# Shape of the dataset
df_list = [flight_df, hotel_df, user_df]
df_name_list = ['flight_df', 'hotel_df', 'user_df']

for df_name, df in zip(df_name_list, df_list):
    print(f'Total no. of rows and columns in {df_name}: {df.shape}')

# Dataset Info
for df_name, df in zip(df_name_list, df_list):
    print(f'{df_name} Dataset Info:-')
    print(df.info())

# Summary statistics of numeric columns
for df_name, df in zip(df_name_list, df_list):
    print(f'{df_name} Dataset Summary Statistics:-')
    print(df.describe())

# Summary statistics of categorical columns
for i, df in zip(df_name_list, df_list):
    print(f'{i} Dataset Summary Statistics:-')
    print(df.describe(include='object'))

# Check for Missing Values
for i, df in zip(df_name_list, df_list):
    print(f'Total no. of null rows in {i}: {df.isnull().sum()}')

# Check for Duplicate rows
for i, df in zip(df_name_list, df_list):
    print(f'Total no. of duplicate rows in {i}: {df.duplicated().sum()}')

"""##**Data Preprocessing**"""

#flight_df1= flight_df.merge(user_df,how='outer',left_on='userCode',right_on='code')

# Converting date column data type into datetime
flight_df['date'] = pd.to_datetime(flight_df['date'])

# Extracting WeekNo., Month, Year, Weekday from date column
flight_df['week_day'] = flight_df['date'].dt.weekday
flight_df['month'] = flight_df['date'].dt.month
flight_df['week_no'] = flight_df['date'].dt.isocalendar().week
flight_df['year'] = flight_df['date'].dt.year
flight_df['day'] = flight_df['date'].dt.day

flight_df.head()

"""### Filtering the dataframe based on relevant column"""

flights_filtered= flight_df[['from','to','flightType','agency','time','distance','week_day','week_no','day','month','year','price']]
flights_filtered.head()

flights_filtered.shape

"""#**Exploratory Data Analysis**

## **Univariate Analysis**

###**Numerical Coulmn Distribution**

Check for skewness in the distribution of numerical Columns
"""

# Filter only numerical columns
numerical_columns = flights_filtered.select_dtypes(include=['number']).columns

# Calculate skewness for numerical columns
skewness = flights_filtered[numerical_columns].skew()

# Print skewness
print(skewness)

# Select numerical columns only
numerical_columns = flights_filtered.select_dtypes(include=['number']).columns

# Calculate skewness for numerical columns
skewness = flights_filtered[numerical_columns].skew()

# Plot skewness as a bar chart
skewness.plot(kind='bar', figsize=(10, 6), color='skyblue', title="Skewness of Numerical Columns")
plt.xlabel('Columns')
plt.ylabel('Skewness')
plt.show()

"""From the above result, we can check which variable is normally distributed and which is not.

The variables with skewness > 1 price are highly positively skewed.

The variables with skewness < -1 are highly negatively skewed.

The variables with 0.5 < skewness < 1 are moderately positively skewed.

The variables with -0.5 < skewness < -1 are moderately negatively skewed.

And, the variables with -0.5 < skewness < 0.5 are symmetric
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Plot histogram with KDE of the 'time' column
plt.figure(figsize=(10, 6))
sns.histplot(flights_filtered['time'], bins=30, kde=True)
plt.title('Histogram of Travel Time')
plt.xlabel('Travel Time (hrs)')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()

"""Inference from the plot:

The histogram shows the distribution of travel time, with the x-axis representing the travel time and the y-axis representing the frequency (i.e., the number of occurrences) of these travel time.
"""

#Distribution of Distance column
import matplotlib.pyplot as plt
import seaborn as sns

# Plot histogram with KDE of the 'time' column
plt.figure(figsize=(10, 6))
sns.histplot(flights_filtered['distance'], bins=30, kde=True)
plt.title('Histogram of Distance (kms)')
plt.xlabel('Travel Distance (kms)')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()

"""Inference from the plot:

The histogram shows the distribution of travel distance, with the x-axis representing the travel distance and the y-axis representing the frequency (i.e., the number of occurrences) of these travel distance.
"""

# Flight Price Distribution
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(flights_filtered['price'], bins=30, kde=True)
plt.title('Histogram of Price Distribution ')
plt.xlabel('Flight Price')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()

"""Inference from the plot:

The majority of the prices seem to be concentrated in a relatively narrow range, indicating a common price range for these travel packages.

There is a long tail on the right side of the distribution, suggesting that there are a few travel packages with significantly higher prices compared to the majority.

The distribution appears to be right-skewed, with prices tapering off as they increase.

Overall, this plot provides insight into the distribution of prices, which is valuable information for understanding the pricing structure of the travel packages in the dataset.
"""

# Plot histograms for numeric columns
numeric_cols = flights_filtered.select_dtypes(include=['int64', 'float64']).columns
flights_filtered[numeric_cols].hist(bins=20, figsize=(12, 8))
plt.show()

"""### **Check for Outliers in Numerical Coulmns using Box-plot**

If the distribution of numerical column follows normal distribution, then use standad deviation to handle outliers.

Otherwise we will use IQR technique to handle outliers
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Define a function to plot box plots
def plot_boxplot(data, column_name, figsize=(12, 8)):
    plt.figure(figsize=figsize)
    sns.boxplot(data=data[column_name])
    plt.xticks(rotation=45)
    plt.title(f'Boxplot of {column_name}')
    plt.show()

# Plot box plots for 'time' and 'price' columns
plot_boxplot(flights_filtered, 'time')
plot_boxplot(flights_filtered, 'price')
plot_boxplot(flights_filtered, 'distance')

"""### **Distribution of Categorical Coulmns using Count-plot**"""

flights_filtered.info()

import seaborn as sns
import matplotlib.pyplot as plt

# List of columns to plot countplots for
columns_to_plot = ['flightType', 'agency', 'month']
data = [flights_filtered, flights_filtered, flights_filtered]  # Corresponding data for each plot

# Define a function to plot countplots
def plot_countplot(data, column_name, palette="Set2", figsize=(10, 6)):
    plt.figure(figsize=figsize)
    sns.countplot(x=column_name, data=data, palette=palette)
    plt.title(f'Countplot of {column_name}')
    plt.xticks(rotation=45)
    plt.show()

# Plot countplots for the specified columns
for col, df in zip(columns_to_plot, data):
    plot_countplot(df, col)

"""### **Distribution of Categorical Coulmns using pie-chart**"""

import matplotlib.pyplot as plt

# Define a function to create and display pie charts
def plot_pie_chart(data, column_name, title, figsize=(8, 8)):
    counts = data[column_name].value_counts()
    print(f'{column_name} counts:\n{counts}')
    plt.figure(figsize=figsize)
    plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90)
    plt.title(title)
    plt.axis('equal')  # Ensures the pie chart is a circle
    plt.show()

# Plot pie charts for different columns
plot_pie_chart(flights_filtered, 'flightType', 'Distribution of Flight Types')
plot_pie_chart(flights_filtered, 'agency', 'Distribution of Agency')
plot_pie_chart(flights_filtered, 'to', 'Distribution of Destination Cities')

"""Inference from the plot:

The pie chart illustrates the distribution of selected package types in the dataset. The data is categorized into three package types: Firstclass, economic, Premium.

Firstclass and Premium are the most common package types, each making up a significant portion of the dataset.
economic is also fairly common, but slightly less frequent than Deluxe and Standard.

### **Distribution of Values in Numerical Coulmns using a pie-chart**
"""

import matplotlib.pyplot as plt

# Define a function to create and display pie charts
def plot_pie_chart(data, column_name, title, figsize=(8, 8)):
    counts = data[column_name].value_counts()
    print(f'{column_name} counts:\n{counts}')
    plt.figure(figsize=figsize)
    plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90)
    plt.title(title)
    plt.axis('equal')  # Ensures the pie chart is a circle
    plt.show()

# Plot pie charts for numerical columns with discrete values
plot_pie_chart(flights_filtered, 'week_day', 'Distribution of Week Days')
plot_pie_chart(flights_filtered, 'year', 'Distribution of Year')

"""## **Bivariate Analysis**

### **Check for Linear relationship btwn Independent numerical Variable and Target variable**
"""

# Price vs. Travel Time

plt.figure(figsize=(10, 6))
sns.scatterplot(data=flights_filtered, x='time', y='price', color='purple', alpha=0.5)
plt.title('Flight Price vs. Travel Time')
plt.xlabel('Travel Time')
plt.ylabel('Flight Price')
plt.show()

# Price vs. Travel Distance

plt.figure(figsize=(10, 6))
sns.scatterplot(data=flights_filtered, x='distance', y='price', color='purple', alpha=0.5)
plt.title('Flight Price vs. Travel Distance')
plt.xlabel('Travel Distance')
plt.ylabel('Flight Price')
plt.show()

"""1. **Price vs. Hotel Ratings Plot**:
   - The plot examines the relationship between "Hotel Ratings" and "Per Person Price" for travel packages.
   - Each point represents a travel package, with its price on the y-axis and hotel ratings on the x-axis.

2. **Inference**:
   - There doesn't seem to be a strong linear correlation between hotel ratings and per person price.
   - Most data points are scattered across the plot, indicating that hotel ratings alone may not be a dominant factor in determining the price of travel packages.
   - However, there are some clusters of points, suggesting that specific rating ranges may have an impact on price within certain regions.

### **Check for Outliers in Categorical Coulmns**
"""

# Box Plots:
# Visualize the distribution of prices per agency type:

plt.figure(figsize=(12, 6))
sns.boxplot(data=flights_filtered, x='agency', y='price')
plt.xticks(rotation=90)
plt.xlabel('Agency Type')
plt.ylabel('Flight Price')
plt.title('Price Distribution by Agency Type')
plt.show()

# Box Plots:
# Visualize the distribution of prices per Flight type:

plt.figure(figsize=(12, 6))
sns.boxplot(data=flights_filtered, x='flightType', y='price')
plt.xticks(rotation=90)
plt.xlabel('Flight Type')
plt.ylabel('Flight Price')
plt.title('Price Distribution by Flight Type')
plt.show()

# Box Plots:
# Visualize the distribution of prices per Destination Cities:

plt.figure(figsize=(12, 6))
sns.boxplot(data=flights_filtered, x='to', y='price')
plt.xticks(rotation=90)
plt.xlabel('Destination Cities')
plt.ylabel('Flight Price')
plt.title('Price Distribution by Destination Cities')
plt.show()

"""**Inference of the plot**:

1. **Variability**: The box plots reveal varying levels of price variability within different package types. Some package types have a wider range of prices (larger boxes), while others have narrower ranges (smaller boxes).

2. **Outliers**: Outliers, represented as individual points beyond the "whiskers" of the boxes, can be seen in several package types. These outliers indicate some extreme price values within those categories.

3. **Median Prices**: The horizontal line inside each box represents the median price for each package type. It's a quick way to compare the typical prices across different categories.

4. **Package Type Impact**: The plot provides a visual sense of how package type influences price distribution. Some package types consistently have higher or lower prices than others.

###**Visualize the distribution of prices per Categorical Coulmns using bar-plot**
"""

sns.barplot(x='flightType',y='price', data=flights_filtered)

"""The mean most expensive flight Class Type was the FirstClass, followed by Premium Class and Economic Class."""

sns.barplot(x='agency',y='price', data=flights_filtered)

"""The mean most expensive flight tickets booked by agency was Flyingdrops, followed by Rainbow Class and Cloudfy agency.

## **Multi-Variate Analysis**
"""

# Bar Plots:
# Explore the relationship between the agency and flight types:

plt.figure(figsize=(12, 6))
sns.barplot(data=flights_filtered, x='agency', y='price', hue='flightType')
plt.xticks(rotation=90)
plt.xlabel('Agency')
plt.ylabel('Flight Price')
plt.title('Flight Price by Agency and Flight Type')
plt.show()

# Stacked Bar Plot:
# Show the distribution of flight types by agency using a stacked bar plot:

flight_package_counts = flights_filtered.groupby(['agency', 'flightType']).size().unstack(fill_value=0)
flight_package_counts.plot(kind='bar', stacked=True, figsize=(12, 6))
plt.xlabel('Agency')
plt.ylabel('Count')
plt.title('Distribution of Flight Types by Agency (Stacked Bar Plot)')
plt.xticks(rotation=45)
plt.show()

"""Inference of the plot:

The plot shows that the agency Flyingdrops is quite popular in booking only first class tickets to its customers and no bookings in any other flight type"

On the contrary, rest two agencies are helping their customers to book their tickets in various flight Class apart from First Class. Both these agencies work in pretty much similar price ranges.

This information suggests that Flyingdrops only deals with HNI or Premium Customers and there is no diverse option apart from FirstClass Type for the customers.

Inference from the plot:

The stacked bar plot visualizes the distribution of package types by start city in the dataset.

In each start city, the stacked bars represent the different package types (Deluxe, Standard, Premium, Luxury, Budget).
For example, in New Delhi Deluxe and Standard packages are more prevalent
This plot allows you to see how the distribution of package types varies across both start cities, providing insights into regional preferences for package types.
"""

!pip install wordcloud

# Word Clouds:
# If you want to visualize common words in text columns like "Boarding City," you can create a word cloud:
from wordcloud import WordCloud

wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(flight_df['from']))
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud - Boarding City')
plt.show()

# Word Clouds:
# If you want to visualize common words in text columns like "Destination," you can create a word cloud:

from wordcloud import WordCloud

wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(flight_df['to']))
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud - Destination')
plt.show()

"""Inference from the plot:

The word cloud plot for the "Destination" column visually represents the most common words found in the text data. From the plot, it appears that some of the frequently mentioned destinations include Florianopolis, Grande, Sao Paulo, Brasilia DF, Natal RN and Aracaju SE. These destinations seem to be popular or commonly mentioned in the dataset.

# **Feature Engineering**
"""

# renaming the Column name from "to" to "destination"
flights_filtered.rename(columns={"to":"destination"},inplace=True)

# Creating a new feature using distance and time columns
flights_filtered['flight_speed']=round(flights_filtered['distance']/flights_filtered['time'],2)

flights_filtered.head()

"""### Now we are checking for outliers in flight_speed column by using Box_plot"""

sns.boxplot(x=flights_filtered['flight_speed'])

"""We can see there are few outliers.

### Checking outliers using IQR method
"""

Q1= np.percentile(flights_filtered['flight_speed'],25)
Q3= np.percentile(flights_filtered['flight_speed'],75)
IQR= Q3-Q1

lower_bound= Q1-IQR*1.5
upper_bound= Q3+IQR*1.5
print(lower_bound,upper_bound)

"""
Here's a revised explanation with the updated perspective on the outliers in the distribution of the flight speed column:

The distribution of the flight speed column in the above graph appears to be left-skewed, with outliers visible in the box plot below the flight speed of 383 km/hr. However, these data points should not be treated as outliers in this case.

Upon closer inspection, these speeds likely occurred due to bad weather conditions, which are valid real-world scenarios affecting flight speeds. Instead of removing or imputing these values, they should be retained for analysis, as they can provide critical insights into how external factors influence flight operations.

To further investigate, additional context such as weather data or flight logs could help confirm the reasoning behind these reduced speeds and support better decision-making for operational improvements."""

df=flights_filtered.copy()
df.describe()

flights_filtered.info()

"""**One-hot encoding**"""

# Apply one-hot encoding to specific categorical columns
df = pd.get_dummies(
    df,
    columns=['from', 'destination', 'flightType', 'agency'],
    prefix=['from', 'destination', 'flightType', 'agency']
)

# Display the first few rows of the transformed DataFrame
df.head()

df.shape

"""# **Feature Selection**

##**Feature Selection Using Statistical Test ANNOVA F-Test**
"""

final_df1=df

df.info()

final_df1= df.drop(columns=['time','flight_speed','month','year','distance'],axis=1)

import pandas as pd
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

# Assuming df is your DataFrame with features and target variable 'target'

# Separate features (X) and target variable (y)
X = final_df1.drop('price', axis=1)  # Features
y = final_df1['price']                # Target variable

# Get the numerical features in X
num_features = X.select_dtypes(include=['number']).columns

# If the number of features is less than k, adjust k to the number of available features
k = min(27, len(num_features))  # Ensure k doesn't exceed the number of available features

# ANOVA F-test for numerical features
f_selector = SelectKBest(score_func=f_classif, k=k)
f_selector.fit(X[num_features], y)

# Get indices of top k features
numerical_top_indices = f_selector.get_support(indices=True)

# Combine top indices
top_indices = list(numerical_top_indices)

# Get top k feature names
top_features = X.columns[top_indices]

# Display top k features
print("Top k selected features:")
print(top_features)

!pip install statsmodels

#Multicollinearity
from statsmodels.stats.outliers_influence import variance_inflation_factor
import pandas as pd
import numpy as np

# Define the function to calculate VIF
def calc_vif(df):
    vif_data = pd.DataFrame()
    vif_data["Feature"] = df.columns
    vif_data["VIF"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]
    return vif_data

# Filter numerical columns excluding boolean columns
numerical_columns = flights_filtered.select_dtypes(include=[np.number]).columns

# List of valid numerical columns
valid_columns = ['time', 'distance', 'week_day', 'week_no', 'day', 'month', 'year', 'price', 'flight_speed']

# Ensure all valid columns are numerical
filtered_df = flights_filtered[valid_columns]

# Convert 'UInt32' columns to float64
if 'week_no' in filtered_df.columns:
    filtered_df['week_no'] = filtered_df['week_no'].astype(float)

# Drop any constant or low-variance columns
filtered_df = filtered_df.loc[:, (filtered_df.var() > 0)]

# Check for any missing or infinite values
filtered_df = filtered_df.replace([np.inf, -np.inf], np.nan).dropna()

# Debugging: Inspect the filtered DataFrame
print("Filtered DataFrame Info:")
print(filtered_df.info())

# Calculate VIF
try:
    vif_result = calc_vif(filtered_df)
    print(vif_result)
except Exception as e:
    print(f"Error calculating VIF: {e}")

X.rename(columns={'from_Sao Paulo (SP)':'from_Sao_Paulo (SP)','from_Rio de Janeiro (RJ)':'from_Rio_de_Janeiro (RJ)','from_Campo Grande (MS)':'from_Campo_Grande (MS)',
                                  'destination_Sao Paulo (SP)':'destination_Sao_Paulo (SP)','destination_Rio de Janeiro (RJ)':'destination_Rio_de_Janeiro (RJ)','destination_Campo Grande (MS)':'destination_Campo_Grande (MS)'},inplace=True)

features_ordering=['from_Florianopolis (SC)',
 'from_Sao_Paulo (SP)',
 'from_Salvador (BH)',
 'from_Brasilia (DF)',
 'from_Rio_de_Janeiro (RJ)',
 'from_Campo_Grande (MS)',
 'from_Aracaju (SE)',
 'from_Natal (RN)',
 'from_Recife (PE)',
 'destination_Florianopolis (SC)',
 'destination_Sao_Paulo (SP)',
 'destination_Salvador (BH)',
 'destination_Brasilia (DF)',
 'destination_Rio_de_Janeiro (RJ)',
 'destination_Campo_Grande (MS)',
 'destination_Aracaju (SE)',
 'destination_Natal (RN)',
 'destination_Recife (PE)',
 'flightType_economic',
 'flightType_firstClass',
 'flightType_premium',
 'agency_Rainbow',
 'agency_CloudFy',
 'agency_FlyingDrops',
 'week_no',
 'week_day']

#Ordering features based on flask output
final_features= X[features_ordering]

X1= final_features

# Target variable
y1 = y

# Split the data into training and testing sets
X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)

scaler_new = StandardScaler()

X_train1 = scaler_new.fit_transform(X_train1)
X_test1 = scaler_new.transform(X_test1)

final_features.columns

"""#**Model Building, Training, Cross-Validation, Hyperparameter Tuning & Evaluation**

##**Linear Regression**

###**Baseline Model**
"""

# Create and train the Linear Regression model
linear_model = LinearRegression()
linear_model.fit(X_train1, y_train1)

# Make predictions on the test set
y_pred1 = linear_model.predict(X_test1)

# Evaluate the model
mae_lr = mean_absolute_error(y_test1, y_pred1)
mse_lr = mean_squared_error(y_test1, y_pred1)
rmse_lr = np.sqrt(mse_lr)
r2_lr = r2_score(y_test1, y_pred1)

# Calculate adjusted R-squared for linear regression
n = X_test1.shape[0]
p = X_test1.shape[1]


# Calculate adjusted R-squared
adj_r2_lr = 1 - ((1 - r2_lr) * (n - 1) / (n - p - 1))


plt.scatter(y_test1, y_test1, c='b', label='Actual', alpha=0.5)  # Blue for actual
plt.scatter(y_test1, y_pred1, c='r', label='Predicted', alpha=0.5)  # Red for predicted
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs. Predicted Values")
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

"""###**Model Evaluation**"""

model_result = pd.DataFrame([['Linear Regression Baseline', mse_lr,rmse_lr,mae_lr, r2_lr,adj_r2_lr]],
               columns = ['Model', 'MSE', 'RMSE', 'MAE', 'R2','adj_r2'])

model_result

"""###**Hyperparameter Tuning Linear**"""

# Define hyperparameters and their potential values
param_grid_linear = {
    'fit_intercept': [True, False],
    'positive': [True, False]
}

# Create a GridSearchCV object for Linear Regression
grid_lr = GridSearchCV(linear_model, param_grid_linear, cv=3, scoring='neg_mean_squared_error')
grid_lr.fit(X_train1, y_train1)

# Get the best hyperparameters for Linear Regression
best_linear_reg = grid_lr.best_estimator_

# Perform grid search
best_linear_reg.fit(X_train1, y_train1)

# Print the best hyperparameters
print("Best Hyperparameters for Linear Regression:", grid_lr.best_estimator_)

"""### **Model Evaluation**"""

# Evaluate the model
y_pred_linear_tuned = best_linear_reg.predict(X_test1)

mae_linear_tuned = mean_absolute_error(y_test1, y_pred_linear_tuned )
mse_linear_tuned = mean_squared_error(y_test1, y_pred_linear_tuned )
rmse_linear_tuned = np.sqrt(mse_linear_tuned)
r2_linear_tuned = r2_score(y_test1, y_pred_linear_tuned )
adj_r2_linear_tuned = 1 - ((1 - r2_linear_tuned) * (n - 1) / (n - p - 1))

model = pd.DataFrame([['Linear Regression Tuned',  mse_linear_tuned,rmse_linear_tuned,mae_linear_tuned, r2_linear_tuned,adj_r2_linear_tuned]],
               columns = ['Model', 'MSE', 'RMSE', 'MAE', 'R2','adj_r2'])

model_result = pd.concat([model_result,model],axis=0,ignore_index = True)
model_result

"""##**Lasso Regression**

###**Baseline Model**
"""

from sklearn.linear_model import Lasso
# Basic Lasso Regression
lasso_model = Lasso()  # You can adjust the alpha parameter for regularization strength
lasso_model.fit(X_train1, y_train1)

# Evaluate the model
y_pred_lasso = lasso_model.predict(X_test1)

mae_lasso = mean_absolute_error(y_test1, y_pred_lasso)
mse_lasso = mean_squared_error(y_test1, y_pred_lasso)
rmse_lasso = np.sqrt(mse_lasso)
r2_lasso = r2_score(y_test1, y_pred_lasso)
adj_r2_lasso = 1 - ((1 - r2_lasso) * (n - 1) / (n - p - 1))

plt.scatter(y_test1, y_test1, c='b', label='Actual', alpha=0.5)  # Blue for actual
plt.scatter(y_test1, y_pred_lasso, c='r', label='Predicted', alpha=0.5)  # Red for predicted
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs. Predicted Values")
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

"""### **Model Evaluation**"""

model = pd.DataFrame([['Lasso Regression Baseline',  mse_lasso,rmse_lasso,mae_lasso, r2_lasso,adj_r2_lasso]],
               columns = ['Model', 'MSE', 'RMSE', 'MAE', 'R2','adj_r2'])

model_result = pd.concat([model_result,model],axis=0,ignore_index = True)
model_result

"""###**Hyperparameter Tuning Lasso**"""

# Hyperparameter tuning using GridSearchCV
from sklearn.model_selection import GridSearchCV

# Define hyperparameters and their potential values
param_grid = {
    'alpha': [0.001,0.01, 0.1,0.3,0.5,0.6,0.8, 1.0,10]  # Adjust the range of alpha values as needed
}

# Create a GridSearchCV object for Lasso Regression
grid_search_lasso = GridSearchCV(lasso_model, param_grid, cv=3, scoring='neg_mean_squared_error')

# Perform grid search
grid_search_lasso.fit(X_train1, y_train1)

# Get the best hyperparameters for Lasso Regression
best_lasso_model = grid_search_lasso.best_estimator_

# Fit the best model to the training data
best_lasso_model.fit(X_train1, y_train1)

# Print the best hyperparameters
print("Best Hyperparameters for Lasso Regression:", grid_search_lasso.best_params_)

"""### **Model Evaluation**"""

# Evaluate the model
y_pred_lasso_tuned = best_lasso_model.predict(X_test1)

mae_lasso_tuned = mean_absolute_error(y_test1, y_pred_lasso_tuned )
mse_lasso_tuned = mean_squared_error(y_test1, y_pred_lasso_tuned )
rmse_lasso_tuned = np.sqrt(mse_lasso_tuned)
r2_lasso_tuned = r2_score(y_test1, y_pred_lasso_tuned )
adj_r2_lasso_tuned = 1 - ((1 - r2_lasso_tuned) * (n - 1) / (n - p - 1))

model = pd.DataFrame([['Lasso Regression Tuned',  mse_lasso_tuned,rmse_lasso_tuned,mae_lasso_tuned, r2_lasso_tuned,adj_r2_lasso_tuned]],
               columns = ['Model', 'MSE', 'RMSE', 'MAE', 'R2','adj_r2'])

model_result = pd.concat([model_result,model],axis=0,ignore_index = True)
model_result

"""##**Ridge Regression**

###**Baseline Model**
"""

from sklearn.linear_model import Ridge

# Basic Ridge Regression
ridge_model = Ridge()  # You can adjust the alpha parameter for regularization strength
ridge_model.fit(X_train1, y_train1)

# Evaluate the model
y_pred_ridge = ridge_model.predict(X_test1)

mae_ridge = mean_absolute_error(y_test1, y_pred_ridge)
mse_ridge = mean_squared_error(y_test1,y_pred_ridge)
rmse_ridge = np.sqrt(mse_ridge)
r2_ridge = r2_score(y_test1, y_pred_ridge)
adj_r2_ridge = 1 - ((1 - r2_ridge) * (n - 1) / (n - p - 1))

plt.scatter(y_test1, y_test1, c='b', label='Actual', alpha=0.5)  # Blue for actual
plt.scatter(y_test1, y_pred_ridge, c='r', label='Predicted', alpha=0.5)  # Red for predicted
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs. Predicted Values")
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

"""### **Model Evaluation**"""

model = pd.DataFrame([['Ridge Regression Baseline',  mse_ridge,rmse_ridge,mae_ridge, r2_ridge,adj_r2_ridge]],
               columns = ['Model', 'MSE', 'RMSE', 'MAE', 'R2','adj_r2'])

model_result = pd.concat([model_result,model],axis=0,ignore_index = True)
model_result

"""###**Hyperparameter Tuning Ridge**"""

# Hyperparameter tuning using GridSearchCV
param_grid = {
    'alpha': [0.001,0.01, 0.1,0.3,0.5,0.6,0.8, 1.0,10,20,50]  # Adjust the range of alpha values as needed
}


# Create a GridSearchCV object for Ridge Regression
grid_search_ridge = GridSearchCV(ridge_model, param_grid, cv=3, scoring='neg_mean_squared_error')

grid_search_ridge.fit(X_train1, y_train1)

# Get the best hyperparameters for Ridge Regression
best_ridge_model = grid_search_ridge.best_estimator_

# Perform grid search
best_ridge_model.fit(X_train1, y_train1)

# Print the best hyperparameters
print("Best Hyperparameters for Ridge Regression:", grid_search_ridge.best_estimator_)

"""### **Model Evaluation**"""

# Evaluate the model
y_pred_ridge_tuned = best_ridge_model.predict(X_test1)

mae_ridge_tuned = mean_absolute_error(y_test1, y_pred_ridge_tuned )
mse_ridge_tuned = mean_squared_error(y_test1, y_pred_ridge_tuned )
rmse_ridge_tuned = np.sqrt(mse_ridge_tuned)
r2_ridge_tuned = r2_score(y_test1, y_pred_ridge_tuned )
adj_r2_ridge_tuned = 1 - ((1 - r2_ridge_tuned) * (n - 1) / (n - p - 1))

model = pd.DataFrame([['Ridge Regression Tuned',  mse_ridge_tuned,rmse_ridge_tuned,mae_ridge_tuned, r2_ridge_tuned,adj_r2_ridge_tuned]],
               columns = ['Model', 'MSE', 'RMSE', 'MAE', 'R2','adj_r2'])

model_result = pd.concat([model_result,model],axis=0,ignore_index = True)
model_result

"""##**Decision Tree**

###**Baseline Model**
"""

# Initialize the Decision Tree Regressor model
decision_tree_reg = DecisionTreeRegressor(random_state=42)

# Fit the model on the training data
decision_tree_reg.fit(X_train1, y_train1)

# Make predictions on the test data
y_pred_decision = decision_tree_reg.predict(X_test1)

# Evaluate the model
mse_dt = mean_squared_error(y_test1, y_pred_decision)
rmse_dt = mse_dt**0.5
mae_dt = mean_absolute_error(y_test1, y_pred_decision)
r2_dt = r2_score(y_test1, y_pred_decision)
adj_r2_dt = 1 - ((1 - r2_dt) * (n - 1) / (n - p - 1))

plt.scatter(y_test1, y_test1, c='b', label='Actual', alpha=0.5)  # Blue for actual
plt.scatter(y_test1, y_pred_decision, c='r', label='Predicted', alpha=0.5)  # Red for predicted
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs. Predicted Values")
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

"""### **Model Evaluation**"""

model = pd.DataFrame([['Decision Tree Baseline',  mse_dt,rmse_dt,mae_dt, r2_dt,adj_r2_dt]],
               columns = ['Model', 'MSE', 'RMSE', 'MAE', 'R2','adj_r2'])

model_result = pd.concat([model_result,model],axis=0,ignore_index = True)
model_result

"""###**Hyperparameter tunning**"""

# Define hyperparameters and their potential values
param_grid_dt = {
    'criterion': ['friedman_mse', 'squared_error'],
    'max_depth': [15,30,45],
    'min_samples_split': [2,3,5],
    'max_features': [15,27,'sqrt'],
    'ccp_alpha' :[1,2]
}


# Create a GridSearchCV object for Decision Tree Regressor
grid_search_dt = GridSearchCV(decision_tree_reg, param_grid_dt, cv=3, scoring='neg_mean_squared_error')
grid_search_dt.fit(X_train1, y_train1)

# Get the best hyperparameters for Decision Tree Regressor
best_decision_tree_model = grid_search_dt.best_estimator_

# Print the best hyperparameters
print("Best Hyperparameters for Decision Tree:", grid_search_dt.best_estimator_)

"""### **Model Evaluation**"""

# Evaluate the best model
y_pred_dt_tuned = best_decision_tree_model.predict(X_test1)

mae_dt_tuned = mean_absolute_error(y_test1, y_pred_dt_tuned)
mse_dt_tuned = mean_squared_error(y_test1, y_pred_dt_tuned)
rmse_dt_tuned = np.sqrt(mse_dt_tuned)
r2_dt_tuned = r2_score(y_test1, y_pred_dt_tuned)
adj_r2_dt_tuned = 1 - ((1 - r2_dt_tuned) * (n - 1) / (n - p - 1))

model = pd.DataFrame([['Decision Tree Tuned',  mse_dt_tuned,rmse_dt_tuned,mae_dt_tuned, r2_dt_tuned,adj_r2_dt_tuned]],
               columns = ['Model', 'MSE', 'RMSE', 'MAE', 'R2','adj_r2'])

model_result = pd.concat([model_result,model],axis=0,ignore_index = True)
model_result

"""###**Feature Importance Decision Tree**"""

# Get feature importances
feature_importances_dt_reg = best_decision_tree_model.feature_importances_

import matplotlib.pyplot as plt

# Define feature names
feature_names = X1.columns.tolist()  # Assuming X_train is a DataFrame

# Zip feature names and importances
feature_importances_sorted = sorted(zip(feature_names, feature_importances_dt_reg), key=lambda x: x[1], reverse=True)
sorted_features, sorted_importances = zip(*feature_importances_sorted)

# Create bar plot
plt.figure(figsize=(10, 6))
plt.bar(range(len(sorted_importances)), sorted_importances, align='center')
plt.xticks(range(len(sorted_importances)), sorted_features, rotation=90)
plt.xlabel('Feature')
plt.ylabel('Importance')
plt.title('Decision Tree Regressor Feature Importance (Sorted)')
plt.show()

"""##**Random Forest**

###**Baseline Model**
"""

# Create and train the Linear Regression model
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train1, y_train1)

# Make predictions on the test set
y_pred_rf = rf_model.predict(X_test1)

# Evaluate the model
mae_rf = mean_absolute_error(y_test1,y_pred_rf)
mse_rf = mean_squared_error(y_test1, y_pred_rf)
rmse_rf = np.sqrt(mse_rf)
r2_rf = r2_score(y_test1, y_pred_rf)
adj_r2_rf = 1 - ((1 - r2_rf) * (n - 1) / (n - p - 1))



plt.scatter(y_test1, y_test1, c='b', label='Actual', alpha=0.5)  # Blue for actual
plt.scatter(y_test1, y_pred_rf, c='r', label='Predicted', alpha=0.5)  # Red for predicted
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs. Predicted Values")
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

"""### **Model Evaluation**"""

model = pd.DataFrame([['Random Forest Baseline',  mse_rf,rmse_rf,mae_rf, r2_rf,adj_r2_rf]],
               columns = ['Model', 'MSE', 'RMSE', 'MAE', 'R2','adj_r2'])

model_result = pd.concat([model_result,model],axis=0,ignore_index = True)
model_result

"""###**Hyperparameter tunning**"""

# Define hyperparameters and their potential values
param_grid_rf = {
    'n_estimators': [50, 100],
    'max_depth': [1,5,10],
    'min_samples_split': [2, 5,10],
    'max_features': ['sqrt',27],
    'n_jobs': [2]
}
# Create a GridSearchCV object for Random Forest Regression
grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=3, scoring='neg_mean_squared_error')
grid_search_rf.fit(X_train1, y_train1)
# Get the best hyperparameters for Random Forest Regression
best_rf_model = grid_search_rf.best_estimator_

grid_search_rf.best_estimator_

#Print the best hyperparameters
print("Best Hyperparameters for Random Forest:", grid_search_rf.best_estimator_)

"""


### **Model Evaluation**"""

# Evaluate the best model
y_pred_rf_tuned = best_rf_model.predict(X_test1)

mae_rf_tuned = mean_absolute_error(y_test1, y_pred_rf_tuned)
mse_rf_tuned = mean_squared_error(y_test1, y_pred_rf_tuned)
rmse_rf_tuned = np.sqrt(mse_rf_tuned)
r2_rf_tuned = r2_score(y_test1, y_pred_rf_tuned)
adj_r2_rf_tuned = 1 - ((1 - r2_rf_tuned) * (n - 1) / (n - p - 1))

model = pd.DataFrame([['Random Forest Tuned',  mse_rf_tuned,rmse_rf_tuned,mae_rf_tuned, r2_rf_tuned,adj_r2_rf_tuned]],
               columns = ['Model', 'MSE', 'RMSE', 'MAE', 'R2','adj_r2'])

model_result = pd.concat([model_result,model],axis=0,ignore_index = True)
model_result

"""###**Feature Importance Random Forest**"""

feature_importances_rf_reg = best_rf_model.feature_importances_

import matplotlib.pyplot as plt

# Define feature names
feature_names = X1.columns.tolist()  # Assuming X_train is a DataFrame

# Zip feature names and importances
feature_importances_sorted = sorted(zip(feature_names, feature_importances_rf_reg), key=lambda x: x[1], reverse=True)
sorted_features, sorted_importances = zip(*feature_importances_sorted)

# Create bar plot
plt.figure(figsize=(10, 6))
plt.bar(range(len(sorted_importances)), sorted_importances, align='center')
plt.xticks(range(len(sorted_importances)), sorted_features, rotation=90)
plt.xlabel('Feature')
plt.ylabel('Importance')
plt.title('Random Forest Feature Importance (Sorted)')
plt.show()

"""##**XGBoost**

###**Baseline Model**
"""

# Import the XGBRegressor class
from xgboost import XGBRegressor
# Define Basic XGBoost regressor
xgb_regressor_model = XGBRegressor(random_state=42)
xgb_regressor_model.fit(X_train1, y_train1)

# Evaluate the model
y_pred_xgb = xgb_regressor_model.predict(X_test1)

mae_xgb = mean_absolute_error(y_test1, y_pred_xgb)
mse_xgb = mean_squared_error(y_test1,y_pred_xgb)
rmse_xgb = np.sqrt(mse_xgb)
r2_xgb = r2_score(y_test1, y_pred_xgb)
adj_r2_xgb = 1 - ((1 - r2_xgb) * (n - 1) / (n - p - 1))

plt.scatter(y_test1, y_test1, c='b', label='Actual', alpha=0.5)  # Blue for actual
plt.scatter(y_test1, y_pred_xgb, c='r', label='Predicted', alpha=0.5)  # Red for predicted
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs. Predicted Values")
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

"""### **Model Evaluation**"""

model = pd.DataFrame([['XGBoost Baseline',  mse_xgb,rmse_xgb,mae_xgb, r2_xgb,adj_r2_xgb]],
               columns = ['Model', 'MSE', 'RMSE', 'MAE', 'R2','adj_r2'])

model_result = pd.concat([model_result,model],axis=0,ignore_index = True)
model_result

"""###**Hyperparameter tunning**"""

# !pip uninstall scikit-learn xgboost
# !pip install scikit-learn xgboost

import xgboost as xgb
import sklearn

print(f"xgboost version: {xgb.__version__}")
print(f"scikit-learn version: {sklearn.__version__}")

from xgboost.sklearn import XGBRegressor
param_grid = {
    'n_estimators': [3, 5],
    'max_depth': [35, 50],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'learning_rate': [0.1]
}
from sklearn.model_selection import RandomizedSearchCV

# Perform RandomizedSearchCV for hyperparameter tuning
random_search_xgb = RandomizedSearchCV(estimator=xgb_regressor_model, param_distributions=param_grid, n_iter=10, cv=3, scoring='neg_mean_squared_error', random_state=42)

# Fit the model
random_search_xgb.fit(X_train1, y_train1)

# Get the best model and parameters
best_xgb_regressor = random_search_xgb.best_estimator_
print("Best hyperparameters:", random_search_xgb.best_params_)

random_search_xgb.best_params_

# Print the best hyperparameters
print("Best Hyperparameters for XGBoost Regressor:", random_search_xgb.best_params_)

"""### **Model Evaluation**

"""

# Evaluate the best model
y_pred_xgb_tuned = best_xgb_regressor.predict(X_test1)

mae_xgb_tuned = mean_absolute_error(y_test1, y_pred_xgb_tuned)
mse_xgb_tuned = mean_squared_error(y_test1, y_pred_xgb_tuned)
rmse_xgb_tuned = np.sqrt(mse_xgb_tuned)
r2_xgb_tuned = r2_score(y_test1, y_pred_xgb_tuned)
adj_r2_xgb_tuned = 1 - ((1 - r2_xgb_tuned) * (n - 1) / (n - p - 1))

model = pd.DataFrame([['XGBosst Model Tuned',  mse_xgb_tuned,rmse_xgb_tuned,mae_xgb_tuned, r2_xgb_tuned,adj_r2_xgb_tuned]],
               columns = ['Model', 'MSE', 'RMSE', 'MAE', 'R2','adj_r2'])

model_result = pd.concat([model_result,model],axis=0,ignore_index = True)
model_result

y_pred_rf = best_xgb_regressor.predict(X_test1)
y_pred_rf_tr = best_xgb_regressor.predict(X_train1)

#Training data Metrics

mse_rf_tr = mean_squared_error(y_train1, y_pred_rf_tr)
rmse_rf_tr = np.sqrt(mse_rf_tr)
mae_rf_tr = mean_absolute_error(y_train1, y_pred_rf_tr)
r2_rf_tr = r2_score(y_train1, y_pred_rf_tr)
adj_r2_rf_tr = 1 - ((1 - r2_rf_tr) * (n - 1) / (n - p - 1))

#Test data Metrics
mse_rf = mean_squared_error(y_test1, y_pred_rf)
rmse_rf = np.sqrt(mse_rf)
mae_rf = mean_absolute_error(y_test1, y_pred_rf)
r2_rf = r2_score(y_test1, y_pred_rf)
adj_r2_rf = 1 - ((1 - r2_rf) * (n - 1) / (n - p - 1))

print("\nRandom Forest Regression Train Metrics:")
print("Mean Squared Error (MSE):", mse_rf_tr)
print("Root Mean Squared Error (RMSE):", rmse_rf_tr)
print("Mean Absolute Error (MAE):", mae_rf_tr)
print("R-squared (R2) Score:", r2_rf_tr)
print("Adjusted R-squared (Adj R2) Score:", adj_r2_rf_tr)


print("\nRandom Forest Regression Test Metrics:")
print("Mean Squared Error (MSE):", mse_rf)
print("Root Mean Squared Error (RMSE):", rmse_rf)
print("Mean Absolute Error (MAE):", mae_rf)
print("R-squared (R2) Score:", r2_rf)
print("Adjusted R-squared (Adj R2) Score:", adj_r2_rf)

"""###**Feature Importance XGBoost**"""

feature_importances_xgb_reg = best_xgb_regressor.feature_importances_

import matplotlib.pyplot as plt

# Define feature names
feature_names = X1.columns.tolist()  # Assuming X_train is a DataFrame

# Zip feature names and importances
feature_importances_sorted = sorted(zip(feature_names, feature_importances_xgb_reg), key=lambda x: x[1], reverse=True)
sorted_features, sorted_importances = zip(*feature_importances_sorted)

# Create bar plot
plt.figure(figsize=(10, 6))
plt.bar(range(len(sorted_importances)), sorted_importances, align='center')
plt.xticks(range(len(sorted_importances)), sorted_features, rotation=90)
plt.xlabel('Feature')
plt.ylabel('Importance')
plt.title('XGBoost Regressor Feature Importance (Sorted)')
plt.show()

"""#**Benchmark Models**"""

#Benchmark Model on the basis on RMSE metric
model_result[model_result['RMSE']==model_result['RMSE'].min()]

#Benchmark Model on the basis on Adjusted R2 square metric
model_result[model_result['adj_r2']==model_result['adj_r2'].max()]

#Benchmark Models on the basis of RMSE and adjusted R2 square metrics were as follows

filtered_result = model_result[(model_result['adj_r2'] == model_result['adj_r2'].max()) | (model_result['RMSE'] == model_result['RMSE'].min())]
filtered_result

"""Key metrics to evaluate:

**Mean Squared Error (MSE):**

Lower MSE indicates a better model.
Decision Tree Tuned has an MSE of 44.42886, which is quite low compared to other models like XGBoost Tuned (MSE = 366,076), Random Forest Tuned (MSE = 17,801), etc.

**Root Mean Squared Error (RMSE):**

RMSE is the square root of MSE, providing error in the same units as the target variable.
Decision Tree Tuned has an RMSE of 6.67, which is very small.

**Mean Absolute Error (MAE):**

MAE represents the average of the absolute errors, and lower values indicate a better model.
Decision Tree Tuned has an MAE of 4.02, which is also very low.

**R-Squared (R²):**

R² represents the proportion of variance explained by the model. A value closer to 1 is preferred.
Decision Tree Tuned has an R² of 0.999663, which is very close to 1, indicating that the model explains almost all of the variance in the data.

**Adjusted R-Squared (adj. R²):**

Adjusted R² adjusts R² for the number of predictors in the model. Higher values suggest a better fit.
Decision Tree Tuned has an adjusted R² of 0.999663, which is very close to R² and indicates an excellent fit.

**Random Forest Tuned: **
Even though it has a slightly higher error (MSE = 17,801) compared to the Decision Tree Tuned model, it is less likely to overfit because it averages predictions across multiple decision trees. This reduces the variance and makes it more robust to overfitting, especially when compared to a single decision tree.
The Random Forest Tuned model has an R² of 0.864901, which is much more reasonable, suggesting that it has better generalizability compared to the Decision Tree, which shows perfect fit.
Additionally, Random Forest models are typically more stable and perform better in terms of generalization, even if they show slightly higher error on training data, as they don't overfit as much as a single decision tree might.

**Conclusion:**

1. Overfitting in Decision Tree Tuned is a significant concern, as its perfect R² could indicate that it is memorizing the training data, rather than learning patterns that generalize well to unseen data.
2. Random Forest Tuned is likely the better choice for this case, as it provides a balance of good performance metrics (MSE, RMSE, MAE) while being less prone to overfitting compared to a single Decision Tree.
3. XGBoost Tuned, with its negative R², should likely be avoided, as it indicates a poor model fit.
4. **Random Forest Tuned** is therefore the best model when considering overfitting, as it achieves a reasonable trade-off between bias and variance and is less likely to suffer from the extreme overfitting observed with Decision Tree models.
"""

plt.figure(figsize=(10, 6))

# Linear Regression
plt.scatter(y_test1, y_pred_linear_tuned, label='Linear Regression', alpha=0.6)

# Lasso Regression
#plt.scatter(y_test1, y_pred_lasso_tuned, label='Lasso Regression', alpha=0.6)

# Ridge Regression
#plt.scatter(y_test1, y_pred_ridge_tuned, label='Ridge Regression', alpha=0.6)

# ElasticNet
#plt.scatter(y_test1, y_pred_elastic_tuned, label='ElasticNet', alpha=0.6)

# Decision Tree Regressor
plt.scatter(y_test1, y_pred_dt_tuned, label='Decision Tree', alpha=0.6)

# Random Forest Regressor
plt.scatter(y_test1, y_pred_rf_tuned, label='Random Forest', alpha=0.6)

# XGBoost Regressor
plt.scatter(y_test1, y_pred_xgb_tuned, label='XGBoost', alpha=0.6)

plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs. Predicted Values")
plt.legend()
plt.show()

plt.figure(figsize=(10, 6))

# Linear Regression Residuals
residuals_lr = y_test1 - y_pred_linear_tuned
plt.scatter(y_pred_linear_tuned, residuals_lr, label='Linear Regression', alpha=0.6)

# Random Forest Regressor Residuals
residuals_rf = y_test1 - y_pred_rf_tuned
plt.scatter(y_pred_rf_tuned, residuals_rf, label='Random Forest', alpha=0.6)

# Decision Tree Regressor Residuals
residuals_dt = y_test1 -y_pred_dt_tuned
plt.scatter(y_pred_dt_tuned, residuals_dt, label='Decision Tree', alpha=0.6)

# XGBoost Regressor Residuals
residuals_xgb = y_test1 -y_pred_xgb_tuned
plt.scatter(y_pred_xgb_tuned, residuals_xgb, label='XGBoost', alpha=0.6)

plt.axhline(0, color='black', linestyle='--', lw=2)
plt.xlabel("Predicted Values")
plt.ylabel("Residuals")
plt.title("Residual Plot")
plt.legend()
plt.show()

plt.figure(figsize=(10, 6))

# Linear Regression Residuals Distribution
plt.hist(residuals_lr, bins=30, alpha=0.6, label='Linear Regression')

# Random Forest Regressor Residuals Distribution
plt.hist(residuals_rf, bins=30, alpha=0.6, label='Random Forest')

# Decision Tree Regressor Residuals Distribution
plt.hist(residuals_dt, bins=30, alpha=0.6, label='Decision Tree')

# XGBoost Regressor Residuals Distribution
plt.hist(residuals_xgb, bins=30, alpha=0.6, label='XGBoost')

plt.xlabel("Residuals")
plt.ylabel("Frequency")
plt.title("Distribution of Residuals")
plt.legend()
plt.show()

"""##**Feature Selection Using Multicollinearity and Vif Score**"""

#Multicollinearity
from statsmodels.stats.outliers_influence import variance_inflation_factor
def calc_vif(X):

    # Calculating VIF
    vif = pd.DataFrame()
    vif["variables"] = X.columns
    vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

    return(vif)

final_df= flights_filtered.drop(columns=['flight_speed','time','month','year','distance'],axis=1)

# Select only numeric columns
numeric_df = final_df.select_dtypes(include=[float, int])

# Calculate the correlation matrix using only numeric columns
correlation_matrix = numeric_df.corr()
k = 27  # Replace with the desired number of top features
selected_features = correlation_matrix['price'].abs().sort_values(ascending=False).index[1:k+1]

# Create a subset of the DataFrame with the selected features
subset_df = final_df[selected_features]

# Calculate the correlation matrix for the selected features
correlation_matrix = subset_df.corr()

# Set up the plot figure size
plt.figure(figsize=(12, 8))

# Create a heatmap of the correlation matrix
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")

# Set the plot title
plt.title('Correlation Matrix of Selected Features')

# Show the plot
plt.show()

calc_vif(flights_filtered[[i for i in flights_filtered.describe().columns if i  in selected_features]])

"""# **Flask Building**

Things we need to do:

**Flask Web Application**: We create a Flask web application to serve as an API endpoint.

**Load Trained Model**: We load a trained regression model (you should replace this with your actual model loading code).

**Prediction Function**: We define a function (predict_value) to make predictions using the loaded model.

**User Input Processing**: In the /predict route, we collect user input data from an HTML form, including price, travel details, and other parameters.

**Data Preparation**: We prepare the user input data and convert it into a format suitable for making predictions.

**Prediction**: Using the loaded model, we make predictions based on the user's input.

**JSON Response**: We return the prediction result as a JSON response to the API request.

**HTML Form**: If the request is a GET request, we display an HTML form to collect user input.

**Styling**: You can customize the HTML form and add CSS styling to make it visually appealing.

**Run the Flask App**: The Flask app is run, allowing users to access it and receive predictions through API requests.
"""

import pickle
pickle.dump(scaler_new,open('/content/drive/MyDrive/travel_capstone/scaling.pkl','wb'))
pickle.dump(best_rf_model,open('/content/drive/MyDrive/travel_capstone/rf_model.pkl','wb'))

pickle.dump(best_linear_reg,open('/content/drive/MyDrive/travel_capstone/lr_model.pkl','wb'))
pickle.dump(best_lasso_model,open('/content/drive/MyDrive/travel_capstone/lasso_model.pkl','wb'))
pickle.dump(best_ridge_model,open('/content/drive/MyDrive/travel_capstone/ridge_model.pkl','wb'))
pickle.dump(best_decision_tree_model,open('/content/drive/MyDrive/travel_capstone/dt_model.pkl','wb'))
pickle.dump(best_xgb_regressor,open('/content/drive/MyDrive/travel_capstone/xgb_model.pkl','wb'))

with open("/content/drive/MyDrive/travel_capstone/scaling.pkl", "wb") as f:
    pickle.dump(scaler_new, f)

scaler_model=pickle.load(open('/content/drive/MyDrive/travel_capstone/scaling.pkl','rb'))
xgb_model=pickle.load(open('/content/drive/MyDrive/travel_capstone/xgb_model.pkl','rb'))

# Create a function for prediction
def predict_price(input_data, model,scaler):
    # Prepare the input data

    # Initialize an empty DataFrame
    df_input2 = pd.DataFrame([input_data])

    # Independent features
    X = df_input2

    # Scale the data using the same scaler used during training
    X = scaler.transform(X)

    # Make predictions using the trained Decision model
    y_pred = model.predict(X)

    return y_pred[0]

"""##**Testing Pickled model**"""

df_input = pd.read_csv('/content/drive/MyDrive/travel_capstone/flights.csv',on_bad_lines='skip')


df_input['date'] = pd.to_datetime(df_input['date'])
df_input['day'] = df_input['date'].dt.day
df_input['date'] = pd.to_datetime(df_input['date'])
df_input['week_no'] = df_input['date'].dt.isocalendar().week
df_input['week_day'] = df_input['date'].dt.weekday
df_input['month'] = df_input['date'].dt.month
df_input['year'] = df_input['date'].dt.year
df_input['flight_speed'] = df_input['distance']/df_input['time']  # Add flight_speed appropriately


# renaming the Column name
df_input.rename(columns={"to":"destination"},inplace=True)

# one-hot encoding
df_input = pd.get_dummies(df_input, columns=['from','destination','flightType','agency'])

# renaming the Column name
df_input.rename(columns={'from_Sao Paulo (SP)':'from_Sao_Paulo (SP)','from_Rio de Janeiro (RJ)':'from_Rio_de_Janeiro (RJ)','from_Campo Grande (MS)':'from_Campo_Grande (MS)',
                                  'destination_Sao Paulo (SP)':'destination_Sao_Paulo (SP)','destination_Rio de Janeiro (RJ)':'destination_Rio_de_Janeiro (RJ)','destination_Campo Grande (MS)':'destination_Campo_Grande (MS)'},inplace=True)

df_input

"""Y=df_input.loc[:,['from_Florianopolis (SC)',
 'from_Sao_Paulo (SP)',
 'from_Salvador (BH)',
 'from_Brasilia (DF)',
 'from_Rio_de_Janeiro (RJ)',
 'from_Campo_Grande (MS)',
 'from_Aracaju (SE)',
 'from_Natal (RN)',
 'from_Recife (PE)',
 'destination_Florianopolis (SC)',
 'destination_Sao_Paulo (SP)',
 'destination_Salvador (BH)',
 'destination_Brasilia (DF)',
 'destination_Rio_de_Janeiro (RJ)',
 'destination_Campo_Grande (MS)',
 'destination_Aracaju (SE)',
 'destination_Natal (RN)',
 'destination_Recife (PE)',
 'flightType_economic',
 'flightType_firstClass',
 'flightType_premium',
 'agency_Rainbow',
 'agency_CloudFy',
 'agency_FlyingDrops',
 'week_no',
 'week_day',
 'day']]
"""

#ordering features based on requirement
Z=df_input[X1.columns]

#Edited Code
row_index = 10  # Replace with the desired row index

# Access the row from df_input using iloc
input_row = Z.iloc[row_index]

# Create an input dictionary from the selected row
input_data = Z.iloc[row_index].to_dict()
#scaler_model_new1=pickle.load(open('/content/drive/MyDrive/travel_capstone/scaler_new','rb'))
#rf_model_new1=pickle.load(open('/content/drive/MyDrive/travel_capstone/dt_model_new','rb'))
predicted_price = str(round(predict_price(input_data, best_rf_model,scaler_model),2))
print(f'Predicted Flight Price Per Person: ${predicted_price}')

"""#**Flask Code**"""

#Final Flask Code
# Create a function for prediction
import pandas as pd
import pickle
from flask import Flask, request, jsonify

from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


def predict_price(input_data, model, scaler):
    # Prepare the input data

    # Initialize an empty DataFrame
    df_input2 = pd.DataFrame([input_data])

    # Independent features
    X = df_input2

    # Scale the data using the same scaler used during training
    X = scaler.transform(X)

    # Make predictions using the trained Decision model
    y_prediction = model.predict(X)

    return y_prediction[0]


app = Flask(__name__)


@app.route('/',
           methods=['GET', 'POST'])
def predict():
    return """

<!DOCTYPE html>
<html>
  <head>
    <title>Flight Price Prediction</title>
    <style>
      body {
        font-family: 'Poppins', sans-serif;
        background-color: #f9f9f9;
        margin: 0;
        padding: 0;
      }

      .container {
        max-width: 800px;
        margin: 0 auto;
        padding: 40px;
        background-color: #ffffff;
        border-radius: 10px;
        box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1);
        text-align: center;
      }

      h1 {
        color: #007BFF;
        font-size: 36px;
        margin-bottom: 20px;
      }

      form {
        text-align: left;
      }

      input[type="text"],
      input[type="number"] {
        width: 100%;
        padding: 15px;
        margin: 15px 0;
        border: none;
        border-bottom: 2px solid #007BFF;
        font-size: 18px;
        background-color: transparent;
        color: #333;
        transition: border-bottom 0.3s ease;
      }

      input[type="text"]:focus,
      input[type="number"]:focus {
        border-bottom: 2px solid #0056b3;
        outline: none;
      }

      input[type="checkbox"],
      input[type="radio"] {
        margin-right: 10px;
      }

      input[type="submit"] {
        background-color: #007BFF;
        color: #fff;
        padding: 15px 30px;
        border: none;
        border-radius: 5px;
        cursor: pointer;
        font-size: 20px;
        transition: background-color 0.3s ease;
      }

      input[type="submit"]:hover {
        background-color: #0056b3;
      }

      p#prediction {
        margin-top: 20px;
        font-size: 24px;
        color: #007BFF;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>Flight Price Prediction</h1>
      <form action="/predict" method="POST">
        <b>Select a Boarding City</b>
        <br />
        <br />
        <input type="radio" id="Aracaju" name="from" value="Aracaju">
        <label for="Aracaju">Aracaju</label>
        <br>
        <input type="radio" id="Brasilia" name="from" value="Brasilia">
        <label for="Brasilia">Brasilia</label>
        <br>
        <input type="radio" id="Campo" name="from" value="Campo_Grande">
        <label for="Campo_Grande">Campo_Grande</label>
        <br>
        <input type="radio" id="Florianopolis" name="from" value="Florianopolis">
        <label for="Florianopolis">Florianopolis</label>
        <br>
        <input type="radio" id="Natal" name="from" value="Natal">
        <label for="Natal">Natal</label>
        <br>
        <input type="radio" id="Recife" name="from" value="Recife">
        <label for="Recife">Recife</label>
        <br>
        <input type="radio" id="Rio_de_Janeiro" name="from" value="Rio_de_Janeiro">
        <label for="Rio_de_Janeiro">Rio_de_Janeiro</label>
        <br>
        <input type="radio" id="Salvador" name="from" value="Salvador">
        <label for="Salvador">Salvador</label>
        <br>
        <input type="radio" id="Sao_Paulo" name="from" value="Sao_Paulo">
        <label for="Sao_Paulo">Sao_Paulo</label>
        <br>
        <br />
        <br />
        <b>Select a Destination City</b>
        <br />
        <br />
        <input type="radio" id="Aracaju" name="Destination" value="Aracaju">
        <label for="Aracaju">Aracaju</label>
        <br>
        <input type="radio" id="Brasilia" name="Destination" value="Brasilia">
        <label for="Brasilia">Brasilia</label>
        <br>
        <input type="radio" id="Campo_Grande" name="Destination" value="Campo_Grande">
        <label for="Campo">Campo_Grande</label>
        <br>
        <input type="radio" id="Florianopolis" name="Destination" value="Florianopolis">
        <label for="Florianopolis">Florianopolis</label>
        <br>
        <input type="radio" id="Natal" name="Destination" value="Natal">
        <label for="Natal">Natal</label>
        <br>
        <input type="radio" id="Recife" name="Destination" value="Recife">
        <label for="Recife">Recife</label>
        <br>
        <input type="radio" id="Rio_de_Janeiro" name="Destination" value="Rio_de_Janeiro">
        <label for="Rio_de_Janeiro">Rio_de_Janeiro</label>
        <br>
        <input type="radio" id="Salvador" name="Destination" value="Salvador">
        <label for="Salvador">Salvador</label>
        <br>
        <input type="radio" id="Sao_Paulo" name="Destination" value="Sao_Paulo">
        <label for="Sao_Paulo">Sao_Paulo</label>
        <br>
        <br />
        <br />
        <b>Select a Flight Type</b>
        <br />
        <br />
        <input type="radio" id="flightType_premium" name="flightType" value="premium">
        <label for="flightType_premium">premium</label>
        <br>
        <input type="radio" id="flightType_economic" name="flightType" value="economic">
        <label for="flightType_economic">economic</label>
        <br>
        <input type="radio" id="flightType_firstClass" name="flightType" value="firstClass">
        <label for="flightType_firstClass">firstClass</label>
        <br />
        <br />
        <b>Select Agency</b>
        <br />
        <br />
        <input type="radio" id="FlyingDrops" name="agency" value="FlyingDrops">
        <label for="FlyingDrops">FlyingDrops</label>
        <br>
        <input type="radio" id="Rainbow" name="agency" value="Rainbow">
        <label for="Rainbow">Rainbow</label>
        <br>
        <input type="radio" id="CloudFy" name="agency" value="CloudFy">
        <label for="CloudFy">CloudFy</label>
        <br />
        <br />
        <label for="day">day:</label>
        <input type="number" name="day" min="1" max="31" placeholder="Travel day" value="5">
        <label for="week_no">week_no:</label>
        <input type="number" name="week_no" min="1" max="53" placeholder="Travel Week No" value="7">
        <label for="week_day">week_day No :</label>
        <input type="number" name="week_day" min="1" max="7" placeholder="Travel Week Day" value="5">
        <input type="submit" value="Predict">
      </form>
      <p id="prediction"></p>
    </div>
  </body>
</html>







    """


@app.route('/predict', methods=['POST'])
def index():
    if request.method == 'POST':
        # Get input data from the form
        boarding = str(request.form.get('from'))
        destination = str(request.form.get('Destination'))
        selected_flight_class = str(request.form.get('flightType'))
        selected_agency = str(request.form.get('agency'))
        week_no = int(request.form.get('week_no'))
        week_day = int(request.form.get('week_day'))
        day = int(request.form.get('day'))

        boarding = 'from_' + boarding
        boarding_city_list = ['from_Florianopolis (SC)',
                              'from_Sao_Paulo (SP)',
                              'from_Salvador (BH)',
                              'from_Brasilia (DF)',
                              'from_Rio_de_Janeiro (RJ)',
                              'from_Campo_Grande (MS)',
                              'from_Aracaju (SE)',
                              'from_Natal (RN)',
                              'from_Recife (PE)']

        destination = 'destination_' + destination
        destination_city_list = ['destination_Florianopolis (SC)',
                                 'destination_Sao_Paulo (SP)',
                                 'destination_Salvador (BH)',
                                 'destination_Brasilia (DF)',
                                 'destination_Rio_de_Janeiro (RJ)',
                                 'destination_Campo_Grande (MS)',
                                 'destination_Aracaju (SE)',
                                 'destination_Natal (RN)',
                                 'destination_Recife (PE)']

        selected_flight_class = 'flightType_' + selected_flight_class
        class_list = ['flightType_economic',
                      'flightType_firstClass',
                      'flightType_premium']

        selected_agency = 'agency_' + selected_agency
        agency_list = ['agency_Rainbow',
                       'agency_CloudFy',
                       'agency_FlyingDrops']

        travel_dict = dict()

        for city in boarding_city_list:
            if city[:-5] != boarding:
                travel_dict[city] = 0
            else:
                travel_dict[city] = 1
        for city in destination_city_list:
            if city[:-5] != destination:
                travel_dict[city] = 0
            else:
                travel_dict[city] = 1
        for flight_class in class_list:
            if flight_class != selected_flight_class:
                travel_dict[flight_class] = 0
            else:
                travel_dict[selected_flight_class] = 1
        for agency in agency_list:
            if agency != selected_agency:
                travel_dict[agency] = 0
            else:
                travel_dict[selected_agency] = 1
        travel_dict['week_no'] = week_no
        travel_dict['week_day'] = week_day
        travel_dict['day'] = day

        scaler_model_new=pickle.load(open('/content/drive/MyDrive/travel_capstone/scaling','rb'))
        rf_model_new=pickle.load(open('/content/drive/MyDrive/travel_capstone/rf_model','rb'))
        # Perform prediction using the custom_input dictionary
        predicted_price = str(round(predict_price(travel_dict, rf_model, scaler_model), 2))
        # print(f'Predicted Flight Price Per Person: ${predicted_price}')

        return jsonify({'prediction': predicted_price})


if __name__ == '__main__':
    app.run(debug=True,host="0.0.0.0", port=8001)